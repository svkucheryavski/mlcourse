{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabulære datasæt og klassificering\n",
    "\n",
    "Nu lad os glemme billeder for en stund og tale lidt om mere enkle datasæt - tabulære datasæt. Som det kan ses ud fra navnet, repræsenteres disse datasæt i form af tabeller. Rækkerne i en sådan tabel er enkeltpersoner - objekter, personer, dyr, planter, fænomener - alt hvad du undersøger. Kolonnerne er karakteristika ved disse enkeltpersoner, som du observerer eller måler.\n",
    "\n",
    "For eksempel, hvis du har et datasæt med alle elever i din klasse, så vil hver række svare til en bestemt elev, og hver kolonne til en af deres karakteristika. Det kan være højde, vægt, alder, IQ og andre målbare eller observerbare egenskaber.\n",
    "\n",
    "I dette kursusafsnit vil vi lære:\n",
    "\n",
    "1. Hvordan man opretter sådanne datasæt og indlæser dem fra filer.\n",
    "2. Hvordan man analyserer og visualiserer sådanne datasæt.\n",
    "3. Hvordan man laver en model, som vil tildele enkeltpersonerne til grupper - klassificere dem.\n",
    "4. Hvordan man vurderer resultaterne af en sådan klassificering.\n",
    "\n",
    "Som sædvanlig lad os starte fra bunden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data frames\n",
    "\n",
    "## Data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I Python repræsenteres tabulære datasæt som *data frames*. En data frame ligner meget en Excel-tabel. Den består af en eller flere kolonner, hvor hver kolonne indeholder en specifik type information, typisk enten et tal eller en tekst.\n",
    "\n",
    "Hvis du ønsker at arbejde med data frames, skal du bruge et specielt bibliotek, [Pandas](https://pandas.pydata.org). Lad os først installere det. Kør koden nedenfor og tilføj derefter `#` foran koden for at undgå at køre den igen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu skal vi oprette en datasæt med egenskaber for fire personer. Vi opretter værdier for hver egenskab som en liste (de vil danne kolonnerne i det kommende datasæt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create columns with characteristics of the people as lists\n",
    "Names = [\"John\", \"Jane\", \"David\", \"Emily\"]\n",
    "Age = [18, 25, 23, 28]\n",
    "Height = [1.60, 1.75, 1.65, 1.70]\n",
    "Weight = [62, 78, 59, 73]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu kan vi kombinere listerne sammen, give dem et navn og oprette en data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Pandas library and give it a short name \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "# combine columns to dictionary, create a data frame and show\n",
    "data = pd.DataFrame({'Name': Names, \"Age\": Age, \"Height\": Height, \"Weight\": Weight})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som du kan se, anvendte vi også en specifik datastruktur til at kombinere kolonnerne sammen - en *dictionary*, som ser således ud: `{\"Navn1\": værdier, \"Navn2\": værdier2}`. Dette er en måde i Python at kombinere forskellige elementer, så hvert element har et navn (en nøgle, en ID).\n",
    "\n",
    "Data frames kan også gemmes i filer (eller indlæses fra filer). Den mest passende format til data frames er Coma Separated Values (CSV) filer. De er bare plain tekst filer, hvor værdierne i hver række er adskilt med kommaer. Pandas kan også arbejde med Excel filer efter behov.\n",
    "\n",
    "Lad os gemme vores data frame i en sådan fil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"people.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hvis du kører koden ovenfor, får du en ny fil, `people.csv`, som du kan se i venstre panel i din VSCode. Klik på den for at åbne den, og du vil se følgende:\n",
    "\n",
    "```\n",
    ",Name,Age,Height,Weight\n",
    "0,John,18,1.6,62\n",
    "1,Jane,25,1.75,78\n",
    "2,David,23,1.65,59\n",
    "3,Emily,28,1.7,73\n",
    "```\n",
    "\n",
    "Dette er præcis hvordan data værdierne bliver gemt i filen. Som du kan se, tilføjer Pandas en ekstra kolonne med rækkeindeks foran datakolonnerne. Men resten svarer til data værdierne vi oprettede tidligere. Du kan \"fortælle\" Pandas ikke at tilføje kolonnen med ID'er hvis du specificerer en ekstra parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"people.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hvis du kigger ind i filen nu, vil du se følgende:\n",
    "\n",
    "```\n",
    "Navn,Alder,Højde,Vægt\n",
    "John,18,1.6,62\n",
    "Jane,25,1.75,78\n",
    "David,23,1.65,59\n",
    "Emily,28,1.7,73\n",
    "```\n",
    "\n",
    "Du kan indlæse data fra CSV-filen som følger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv(\"people.csv\")\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Øvelse 1\n",
    "\n",
    "Brug internettet til at indsamle følgende information om alle EU-lande, inklusive:\n",
    "* Navnet på landet\n",
    "* Befolkning\n",
    "* Areal (i kvadratmeter)\n",
    "* År de blev en del af EU\n",
    "* Bruger de euro (bare \"ja\" eller \"nej\")\n",
    "\n",
    "Indtast disse oplysninger i Excel eller andet regnearksoftware og gem tabellen som en CSV-fil (kommasepareret). Indlæs derefter data fra CSV-filen til Python og vis den på skærmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris datasættet\n",
    "\n",
    "[Iris Flower](https://en.wikipedia.org/wiki/Iris_flower_data_set) er et velkendt datasæt, der ofte bruges til indledende formål inden for data science og maskinlæring på grund af dets enkelthed og alsidighed.\n",
    "\n",
    "Dette datasæt består af målinger udført på 150 blomster af tre arter af Iris: *Setosa*, *Versicolor* og *Virginica*. Målingerne inkluderer sepal-længde, sepal-bredde, petal-længde og petal-bredde. Sådan ser blomsterne ud:\n",
    "\n",
    "<img src=\"illustrations/Setosa-Versicolor-Virginica-Images.png\" style=\"max-width:800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordet \"petal\" henviser til den indre, og \"sepal\" henviser til den ydre del af blomsten. Både sepal- og petallængder samt bredde måles i centimeter.\n",
    "\n",
    "<img src=\"illustrations/Petal-Sepal-Length-Width.jpg\" style=\"width:300px; height:300px;\"/>\n",
    "\n",
    "Vi vil bruge denne datasæt til alle eksempler i denne del af kurset. Lad os indlæse datasættet fra filen `Iris.csv` (allerede leveret)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(\"Iris.csv\")\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som du kan se, indeholder datasættet 150 rækker - en for hver enkelt blomst. Kolonnerne inkluderer ID'et (et unikt nummer for hver blomst startende fra 1), de fire målinger og artens navn. Det betyder, at der er én kolonne med heltal, fire kolonner til tal med decimaler og én kolonne med tekstetiketter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag dele af rækkerne\n",
    "\n",
    "Du kan oprette forskellige delmængder af dataframes rækker. For eksempel, for at få kun de første fem eller kun de sidste fem rækker i dataframe anvendes metoderne `head` og `tail`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = d.tail()\n",
    "td.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du kan også angive et specifikt rækkenummer og få værdier for denne række:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get values of row 5 into separate variable and show it\n",
    "r5 = d.iloc[5]\n",
    "r5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her `.iloc` betyder \"position specificeret som indeks\". Du kan også bruge den til at få et subset med flere rækker, ligesom vi gjorde det for NumPy-arrays (husk at indekser i Python altid starter med 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rows from 11 to 15\n",
    "sd = d.iloc[10:15]\n",
    "sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der er også mulighed for at tage ikke-efterfølgende rækker, men f.eks. hver anden eller hver femte række. For at gøre dette skal du tilføje et ekstra tal til indekseringsområdet, som definerer et skridt mellem tallene i sekvensen (vi gjorde dette i den tidligere klasse for at omvende rækkefølgen af rækker og kolonner):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get every fifth row starting from row number 5\n",
    "# remember that in Python indices start from 0 therefore\n",
    "# we have 4 here instead of 5 at the beginning\n",
    "sd = d.iloc[4:150:5]\n",
    "sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det samlede antal rækker (150) er ikke nødvendigt at specificere, du kan bare holde dette sted tomt, som for NumPy-arrays, og Pandas vil forstå, at den skal fortsætte til den sidste række:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = d.iloc[4::5]\n",
    "sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag undermængder af kolonner\n",
    "\n",
    "Du kan også tage værdier fra en bestemt kolonne bare ved at angive dens navn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"Species\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativt kan du også bruge `.iloc` men angive to positioner, rækker og kolonnens indeks, ligesom du gjorde det med 2D NumPy arrays. Hvis du ikke ønsker at udvælge rækker og kun udvælge kolonner, skal du blot bruge `:` symbolet for rækkerne. For eksempel i kodeeksemplet nedenfor tager vi kun kolonner med målinger og viser derefter de første 5 rækker af undersættelsen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all rows and columns from 2 to 5 (from 1 to 4 if we count from 0)\n",
    "X = d.iloc[:, 1:5]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opretter subsets ved brug af logiske udtryk\n",
    "\n",
    "En anden måde at lave rækkesubsets er at bruge logiske udtryk. For eksempel, sådan får du kun rækker, der svarer til *Setosa* arten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"Species\"] == \"setosa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setosa = d[d[\"Species\"] == \"setosa\"]\n",
    "setosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vær opmærksom på, at når vi sammenligner en kolonneværdi med `\"setosa\"`, bruger vi et dobbelt symbol `==`. Dette er den måde at fortælle Python, at du laver sammenligningen, og ikke ønsker at ændre eller tildele en værdi (som vi bruger et enkelt `=` for).\n",
    "\n",
    "Og her er et eksempel, hvor vi opretter en delmængde med kun Setosa blomster, hvis *PetalWidth* er over 0.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(d[\"Species\"] == \"setosa\") & (d[\"PetalWidth\"] > 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setosa2 = d[(d[\"Species\"] == \"setosa\") & (d[\"PetalWidth\"] > 0.3)]\n",
    "setosa2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som du kan se, i dette tilfælde kombinerer vi resultaterne fra to sammenligninger.\n",
    "\n",
    "Én, hvor vi sammenligner værdierne af kolonnen `\"Species\"` med `\"setosa\"`, og den anden, hvor vi sammenligner værdierne fra kolonnen `\"PetalWidth\"` med værdien `0.2` ved hjælp af større operator. Hver sammenligning er placeret inde i parenteser, og der er et ampersand, `&`, imellem.\n",
    "\n",
    "Dette symbol er et synonym for \"og\". Og dermed fortæller denne udtryk Pandas: *vælg rækker, hvor værdien for kolonnen \"Species\" er \"setosa\" **og** værdien for kolonnen \"PetalWidth\" er større end 0,2*. Og dette er præcis hvad vi har fået i den nye dataramme, `setosa2`.\n",
    "\n",
    "\n",
    "### Øvelse 2\n",
    "\n",
    "Hent data om EU-lande fra CSV-filen du tidligere har oprettet. Opret og vis følgende delmængder:\n",
    "\n",
    "* Lande, der blev en del af EU efter år 2000.\n",
    "* Lande, der blev en del af EU efter år 2000 og ikke bruger euro.\n",
    "* Lande, der har et areal på mere end 200.000 kvadratmeter.\n",
    "* Lande, der har en befolkningstæthed på mindre end 50 personer pr. kvadratmeter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisering af data værdier\n",
    "\n",
    ">*Bemærkning til læreren:* start med at forklare hvordan man laver simple grafer ved at bruge manuelt indtastede data værdier. Først som en liste (f.eks. højde og vægt af personer), vis et sprednings- og søjlediagram ved hjælp af dette eksempel. Vis derefter hvordan man laver et sprednings-, linje- og søjlediagram for manuelt indtastede værdier af en parabols punkter. Vis derefter hvordan man genererer disse værdier ved brug af NumPy funktionen `linspace()` og diskutér fordele og ulemper ved NumPy arrays versus simple Python lister.\n",
    "\n",
    "\n",
    "Du kan visualisere data værdier ved hjælp af forskellige grafer. Vi vil genbruge biblioteket `matplotlib` til dette. For eksempel viser koden nedenfor hvor store *Sepal Længde* værdierne er for forskellige blomster ved hjælp af et søjlediagram, så hver blomst er repræsenteret af en søjle, og højden af denne søjle svarer til sepal længden af denne blomst.\n",
    "\n",
    "Vi vil farvelægge søjlerne svarende til de enkelte blomster i henhold til arten. For at gøre dette laver vi tre separate grafer — én for hver art."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save values from column Species into a separate variable\n",
    "species = d[\"Species\"]\n",
    "\n",
    "# create subsets\n",
    "se = d[species == \"setosa\"]\n",
    "ve = d[species == \"versicolor\"]\n",
    "vi = d[species == \"virginica\"]\n",
    "\n",
    "# show size\n",
    "(d.shape, se.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load plotting engine from matplotlib library and give it a short name \"plt\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make a plot figure of size 14 x 5\n",
    "plt.figure(figsize = (14, 5))\n",
    "\n",
    "# show barplot for each species. The location of each bar is defined by ID column\n",
    "# (the ID values are unique) and height of the bar is defined by value from column SepalLength\n",
    "# every bar series has its color and its label\n",
    "plt.bar(se[\"Id\"], se[\"SepalLength\"], color=\"red\", label=\"setosa\")\n",
    "plt.bar(ve[\"Id\"], ve[\"SepalLength\"], color=\"green\", label=\"versicolor\")\n",
    "plt.bar(vi[\"Id\"], vi[\"SepalLength\"], color=\"blue\", label=\"virginica\")\n",
    "\n",
    "# show legend to match colors and labels\n",
    "plt.legend()\n",
    "\n",
    "# add labels\n",
    "plt.ylabel(\"Sepal length\")\n",
    "plt.xlabel(\"Flowers\")\n",
    "plt.title(\"Iris dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hvad nu hvis vi gerne vil lave sådan en graf for hver af de fire målte variabler? Det vil kræve en masse kopiering og indsætning med mange manuelle ændringer. Lad os forenkle dette og lave en dedikeret funktion, der viser et søjlediagram for en hvilken som helst kolonne, hvis navn bruges af en bruger.\n",
    "\n",
    "I denne funktion vil vi også forenkle koden skrevet ovenfor ved at bruge løkker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique value from column species\n",
    "species = d[\"Species\"]\n",
    "species.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the unique values\n",
    "for s in species.unique():\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iris_barplot(d, colname = \"SepalLength\"):\n",
    "    \"\"\" shows bar plot for values from column specified by parameter 'colname' \"\"\"\n",
    "\n",
    "    # make a dictionary with pre-defined colors for each species\n",
    "    colors = {\"setosa\": \"red\", \"virginica\": \"blue\", \"versicolor\": \"green\"}\n",
    "\n",
    "    # get species values to separate variable\n",
    "    species = d[\"Species\"]\n",
    "\n",
    "    # make a loop over unique set of the species values\n",
    "    for s in species.unique():\n",
    "        # create a subset\n",
    "        ds = d[species == s]\n",
    "        # show a plot for the subset\n",
    "        plt.bar(ds[\"Id\"], ds[colname], color=colors[s], label=s)\n",
    "\n",
    "    # add legend, labels and title\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Flowers\")\n",
    "    plt.ylabel(colname)\n",
    "    plt.title(colname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Og nu kan vi genbruge denne funktion til at lave alle fire plots sammen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "iris_barplot(d, \"SepalLength\")\n",
    "plt.subplot(2, 2, 2)\n",
    "iris_barplot(d, \"SepalWidth\")\n",
    "plt.subplot(2, 2, 3)\n",
    "iris_barplot(d, \"PetalLength\")\n",
    "plt.subplot(2, 2, 4)\n",
    "iris_barplot(d, \"PetalWidth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eller på en endnu mere effektiv måde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get column names for specific columns\n",
    "colnames = d.columns[1:5]\n",
    "colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the barplots by using loop over the column names\n",
    "plt.figure(figsize=(20, 15))\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    iris_barplot(d, colnames[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser rigtig godt ud, men det vigtigste er, at det viser os, at blomstermålinger (sidste to grafer) kan bruges til at adskille blomster af forskellige arter. De har tydeligvis forskellig blomsterstørrelse. Vi vil bruge denne viden senere til at opbygge en klassificeringsmodel.\n",
    "\n",
    "I mellemtiden lad os lære, hvordan man laver et andet plot — et spredningsplot. Lad os starte med et simpelt eksempel for at give en idé:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(d[\"PetalLength\"], d[\"PetalWidth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(d[\"PetalLength\"], d[\"PetalWidth\"], marker=\"s\", edgecolor=\"blue\", color=\"yellow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Og her er et langt og fyldigt eksempel, hvor vi genbruger delmængerne, som vi allerede har oprettet ovenfor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a plot figure of size 10 x 10\n",
    "plt.figure(figsize = (6, 6))\n",
    "\n",
    "# show scatter plot which takes values from two columns, Petal Width and Petal Length\n",
    "# and then every row is shown as a point. The x-coordinate of the point corresponds to its\n",
    "# Petal Width value and the y-coordinate to the value of Petal Length.\n",
    "plt.scatter(se[\"PetalWidth\"], se[\"PetalLength\"], color=\"red\", label=\"setosa\")\n",
    "plt.scatter(ve[\"PetalWidth\"], ve[\"PetalLength\"], color=\"green\", label=\"versicolor\")\n",
    "plt.scatter(vi[\"PetalWidth\"], vi[\"PetalLength\"], color=\"blue\", label=\"virginica\")\n",
    "\n",
    "# add axis labels\n",
    "plt.xlabel(\"Petal Width\")\n",
    "plt.ylabel(\"Petal Length\")\n",
    "\n",
    "# show legend to match colors and labels\n",
    "plt.legend()\n",
    "\n",
    "# add a grid\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som du kan se, er koden meget ens med koden, vi brugte til at lave et søjlediagram. Og dette betyder, at vi kan forenkle det og lave en funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iris_scatter(d, x = \"PetalLength\", y = \"PetalWidth\", marker = \"x\"):\n",
    "\n",
    "    # make a dictionary with colors for each species\n",
    "    colors = {\"setosa\": \"red\", \"virginica\": \"blue\", \"versicolor\": \"green\"}\n",
    "\n",
    "    # get species values to separate list\n",
    "    species = d[\"Species\"]\n",
    "\n",
    "    # make a loop over unique set of species values\n",
    "    for s in species.unique():\n",
    "        # create a subset\n",
    "        ds = d[species == s]\n",
    "        #show a plot for the subset\n",
    "        plt.scatter(ds[x], ds[y], color=colors[s], label=s, marker=marker)\n",
    "\n",
    "    # add legend, labels and title\n",
    "    plt.legend()\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    plt.title(\"Iris dataset\")\n",
    "    plt.grid(color = \"lightgray\", linestyle = \":\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Og genbrug det."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 11))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "iris_scatter(d, x = \"SepalLength\", y = \"SepalWidth\")\n",
    "plt.subplot(2, 2, 2)\n",
    "iris_scatter(d, x = \"SepalLength\", y = \"PetalLength\")\n",
    "plt.subplot(2, 2, 3)\n",
    "iris_scatter(d, x = \"PetalLength\", y = \"PetalWidth\")\n",
    "plt.subplot(2, 2, 4)\n",
    "iris_scatter(d, x = \"PetalWidth\", y = \"SepalWidth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eller sådan her:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = d.columns[1:5]\n",
    "colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "plt.figure(figsize=(25, 25))\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        plt.subplot(4, 4, n)\n",
    "        iris_scatter(d, colnames[i], colnames[j])\n",
    "        n = n + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figuren giver et overblik over alle kombinationer af egenskaberne og viser, hvilke der bedst kan bruges til at adskille blomster af forskellige arter. Næste del af kurset forklarer, hvordan man laver en sådan adskillelse, men lad os lave nogle øvelser.\n",
    "\n",
    "### Øvelse 3\n",
    "\n",
    "Skriv en kode, der viser et søjlediagram over arealet af hvert EU-land. Vis de lande, der blev en del af EU før 2000, ved hjælp af blå farve, og landene, der blev en del af EU i 2000 eller senere, ved hjælp af grøn farve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lav et spredningsplot, der viser landenes areal på x-aksen og befolkning på y-aksen. Ser du nogen tendens? Hvorfor?\n",
    "\n",
    "Jeg kan ikke se noget plot, da jeg er en tekstbaseret assistent. Men hvis du laver et spredningsplot med landes areal på x-aksen og befolkning på y-aksen, kan du se om der er en tendens. En mulig trend kunne være, at større lande ofte har en større befolkning, men dette afhænger af data og eventuelle outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Klassifikation* er en proces med at arrangere individer i grupper baseret på ligheder og forskelle i deres egenskaber eller kombinationer. Normalt er klasserne foruddefinerede, så vi kender antallet af klasser og deres navne/etiketter, som f.eks. tilfældet med Iris-datasættet.\n",
    "\n",
    "For at oprette klassifikationsregler eller en klassifikationsmodel har vi brug for individer, hvis klasse tilhør er kendt, så vi kan lære reglerne (og dermed oprette klassifikationsmodellen baseret på disse regler) ved at studere individerne. Og så når vi har et nyt individ, hvis klasse er ukendt, sammenligner klassifikationsmodellen dets egenskaber med det, den ved om klasserne, og træffer en beslutning - hvilken klasse det tilhører, hvis nogen.\n",
    "\n",
    "Klassifikation er en del af den mere generelle disciplin, *maskinlæring*. Tanken med maskinlæring er at lade computeren (computerprogrammet, algoritmen, modellen) lære, hvad der gør individer fra den samme klasse ens, og hvad der gør individer fra forskellige klasser forskellige, og derefter bruge denne viden til at klassificere nye individer, hvis klasse er ukendt.\n",
    "\n",
    "For eksempel kan du oprette en model til at skelne mellem plast- og glasflasker og derefter bruge denne model i en sorteringsmaskine. Eller du kan oprette en model, som genkender ansigterne på dine familiemedlemmer, og derefter bruge den til at låse/oplåse indgangsdøren til dit hus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Træning og test sæt\n",
    "\n",
    "Processen med at udvikle en sådan model kaldes normalt *træning*, da vi *træner* (*underviser*, *styrer*) modellen (mens den *lærer* fra vores træning). For at implementere *træningsprocessen* har du brug for en gruppe individer, hvis klasser er kendte — en *træningssæt*. Så algoritmen kan lære fra træningssættet om ligheder og uligheder.\n",
    "\n",
    "For at kontrollere, hvor godt den trænede model virker, kan vi anvende den på en anden gruppe individer med kendte klasser — en *test sæt*. Det er vigtigt, at selvom individerne i træningssættet og test sættet er taget fra den samme population, er de ikke identiske. Så vi træner modellen ved at bruge én gruppe individer og tester den ved at bruge en anden, uafhængig gruppe.\n",
    "\n",
    "Lad os oprette de to sæt for Iris-dataene. Lad os tage hver femte række ud og bruge den til testning (så vi får 30 blomster i testsættet, 10 for hver art). Og resten — til træning. Sådan gøres det:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate vectors for training and test sets\n",
    "train_ind = d[\"Id\"] % 5 != 0\n",
    "test_ind = d[\"Id\"] % 5 == 0\n",
    "\n",
    "(test_ind[0:10], train_ind[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som du kan se, har vi to kolonner fyldt med værdier `True` og `False` som resultatet.\n",
    "\n",
    "Hvordan virker det? Operatøren `%` beregner resten af en division. Så når du skriver `x % 5`, betyder det \"beregne resten af divisionen af værdien x med 5\". For eksempel, hvis `x = 7`, vil `x % 5` være `2`. Tjek dette i følgende kodeblok:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how % works - try to change x and see what happens when you run the code\n",
    "x = 7\n",
    "x % 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Men når x er lig med 5, 10, 15 eller 55, vil resten være lig med 0. Og dette er præcis hvad vi bruger til at skabe vores indeks. Fordi kolonnen 'Id' indeholder et unikt antal rækker, der starter fra 1, kan vi beregne resten for hvert værdi af denne kolonne og sammenligne den med 0. Alle rækker, hvor denne betingelse er sand, vil blive taget til testsættet. Alle rækker, hvor denne betingelse er falsk, vil blive taget til træningssættet.\n",
    "\n",
    "Lad os oprette sættene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subsets, because \"train_ind\" and \"test_ind\" consists of boolean values (not numbers)\n",
    "# we use \"loc\" (location) instead of \"iloc\" (index location) like we did before.\n",
    "d_train = d.loc[train_ind]\n",
    "d_test = d.loc[test_ind]\n",
    "\n",
    "# show size of each subset\n",
    "(d_train.shape, d_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som du kan se, har vi 120 rækker i træningssættet (40 for hver art) og 30 (10 for hver art) i test-sættet. Lad os se på test-sættet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Og det ser ud som forventet, med 10 individuelle blomstermålinger for hver art."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binær klassifikation\n",
    "\n",
    "Nu er vi klar til at træne en klassifikationsmodel. Men hvad er modellen? Hvilken algoritme skal vi bruge til træning og klassifikation? Hvad skal algoritmen give som resultat?\n",
    "\n",
    "Den enkleste klassifikationsmodel er en *binær klassifikator*, som giver et binært svar — enten `True` (hvis modellen genkender at et eksempel tilhører en bestemt klasse — en *medlem*) eller `False` (hvis modellen afviser eksemplet som tilhørende andre klasser — en *ukendt*). Klassen af interesse i dette tilfælde kaldes en *målklasse*.\n",
    "\n",
    "Lad os oprette en binær klassifikator for klassen *virginica*, blomsterne af denne klasse vises ved brug af blå farve på plottene. Dog i stedet for at bruge fancy algoritmer, og lade computeren lære klassifikationsreglen fra dataen, lad os definere denne regel manuelt, så vi springer maskinlæring over eller tager den fra maskinen og gør det selv.\n",
    "\n",
    "Men lad os træffe vores beslutning baseret på træningssættet alene, som det ville være i en reel træningsproces. Lad os se på plottene for træningssættet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "iris_barplot(d_train, \"SepalLength\")\n",
    "plt.subplot(2, 2, 2)\n",
    "iris_barplot(d_train, \"SepalWidth\")\n",
    "plt.subplot(2, 2, 3)\n",
    "iris_barplot(d_train, \"PetalLength\")\n",
    "plt.subplot(2, 2, 4)\n",
    "iris_barplot(d_train, \"PetalWidth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det ser ud til, at den bedste måde at *skelne* *Virginica* blomsterne fra de to andre arter er at definere en grænse for Blomsterbladets Bredde - Hvis værdien er over 1.7, skal den tilsvarende blomst klassificeres som medlem af klassen *virginica*.\n",
    "\n",
    "Her er søjlediagrammet med beslutningsgrænsen vist som en vandret stiplet linje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "\n",
    "iris_barplot(d_train, \"PetalWidth\")\n",
    "plt.plot(plt.xlim(), [1.7, 1.7], color=\"black\", linestyle=\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som du kan se, vil ikke alle blomster blive klassificeret korrekt i dette tilfælde. Men vi vil diskutere dette senere, lad os implementere beslutningsreglen for én blomst som en lille Python-funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_virginica(flower, threshold = 1.7):\n",
    "    return flower[\"PetalWidth\"] > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test how it works for different rows\n",
    "r = d_train.iloc[101]\n",
    "res = is_virginica(r)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and here how we can turn the True/False values to labels\n",
    "(\"virginica\" if is_virginica(r) else \"non-virginica\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu skal vi skrive en anden funktion, som anvender `is_virginica()` på hver række i en datasæt og returnerer resultaterne af klassifikation som en liste over klasselabels. Den vil tildele label \"virginica\" hvis resultatet af klassifikationen er `True` og \"non-virginica\" hvis det er det modsatte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_isvirginica(d, threshold = 1.7):\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    # we use iterrows() function for data frames which let us\n",
    "    # take every row as a separate object (in this case \"flower\")\n",
    "    for index, flower in d.iterrows():\n",
    "        class_label = \"virginica\" if is_virginica(flower, threshold) else \"non-virginica\"\n",
    "        predictions.append(class_label)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Og anvend det på testsættet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = df_isvirginica(d_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det virker! Lad os sammenligne de faktiske og forudsagte klasser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get column with reference class labels as a separate variable\n",
    "ref = d_test[\"Species\"]\n",
    "\n",
    "# combine the predicted and the reference labels into a new data frame\n",
    "res = pd.DataFrame({\"Reference\": ref, \"Prediction\": pred})\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som du kan se, på den ene side, afviser modellen alle ikke-medlemmer i testsettet - de 10 blomster af *Setosa*-art og 10 blomster af *Versicolor*-art blev korrekt afvist som ikke-medlemmer (fik 'Falsk' som klassifikationssvar).\n",
    "\n",
    "Men samtidig blev tre blomster fra målarten afvist forkert. Er dette et godt resultat? Skal vi ændre tærsklen lidt? Hvordan vurderes kvaliteten af klassifikationen og forbedres den? Lad os tale om dette i næste del."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klassifikationskvalitet\n",
    "\n",
    "For at vurdere klassifikationskvaliteten skal vi tælle, hvor mange resultater der er korrekte, og hvor mange der er forkerte. Der er dog to forskellige grupper af prøver, modellen kan tage fejl af - *fremmede* (objekter, der faktisk ikke tilhører målgruppen) og *medlemmer* (dem, der tilhører denne klasse).\n",
    "\n",
    "Vi skal derfor tælle resultaterne separat. Dette fører os til fire tal:\n",
    "\n",
    "**Korrekte svar**\n",
    "- TP (*sandt positive*) — antal medlemmer, der korrekt accepteres af modellen (får `True`).\n",
    "- TN (*sandt negative*) — antal fremmede, der korrekt afvises af modellen (får `False`).\n",
    "\n",
    "**Forkerte svar (klassifikationsfejl)**\n",
    "- FP (*falsk positive*) — antal fremmede, der forkert accepteres som medlemmer (får `True`).\n",
    "- FN (*falsk negative*) — antal medlemmer, der forkert afvises som fremmede (får `False`).\n",
    "\n",
    "Sådan tæller vi dem for vores eksempel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target class label\n",
    "target_class = \"virginica\"\n",
    "\n",
    "# get reference and predictions as separate variables to make the code shorter\n",
    "ref = res[\"Reference\"]\n",
    "pred = res[\"Prediction\"]\n",
    "\n",
    "# correct decisions — the value for reference class label and predicted class label\n",
    "# are in agreement\n",
    "TP = sum((ref == target_class) & (pred == target_class))\n",
    "TN = sum((ref != target_class) & (pred != target_class))\n",
    "\n",
    "# wrong decisions — the value for reference class label and predicted class label\n",
    "# contradict\n",
    "FN = sum((ref == target_class) & (pred != target_class))\n",
    "FP = sum((ref != target_class) & (pred == target_class))\n",
    "\n",
    "print(TP, TN, FN, FP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som du kan se, stemmer tallene overens med vores manuelle observationer: alle 20 fremmede er korrekt afvist (TN = 20, FP = 0), og kun 7 medlemmer ud af 10 blev korrekt accepteret (TP = 7, FN = 3).\n",
    "\n",
    "Nu kan vi beregne de to statistikker, som vil repræsentere de samme tal, men som en procentdel, så vi får målinger, der ikke afhænger af datasættets størrelse og derfor er lette at forstå.\n",
    "\n",
    "For eksempel er procentdelen af korrekt genkendte medlemmer kaldet en *sensitivitet* og beregnes som forholdet mellem korrekt genkendte medlemmer og det samlede antal medlemmer:\n",
    "\n",
    "$Sensitivitet = TP / (TP + FN)$\n",
    "\n",
    "Den anden statistik er specificitet, det viser procentdelen af fremmede, der blev korrekt afvist af modellen:\n",
    "\n",
    "$Specificitet = TN / (TN + FP)$\n",
    "\n",
    "Lad os beregne dem for vores data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens = TP / (TP + FN)\n",
    "spec = TN / (TN + FP)\n",
    "\n",
    "(sens, spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igen, det matcher vores observationer med 70% korrekt genkendte medlemmer (7 ud af 10) og 100% korrekt afviste fremmede.\n",
    "\n",
    "Endelig kan vi også beregne en tredje statistik, *præcision*, som vil fortælle, hvor godt modellen fungerer generelt. Den beregner simpelthen procentdelen af alle korrekte svar:\n",
    "\n",
    "Præcision = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "Og her er den:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hvis antallet af fremmede og medlemmer i testsættet er ens, vil nøjagtigheden være lig en gennemsnitlig af følsomhed og specificitet som i vores tilfælde.\n",
    "\n",
    "### Øvelse\n",
    "\n",
    "Forestil dig, at vi har trænet en model til at skelne mellem røde æbler og andre. Nedenfor kan du se resultatet af at anvende modellen på testsættet.\n",
    "\n",
    "<img src=\"illustrations/apples-classification.png\" style=\"width: 700px;\">\n",
    "\n",
    "Beregn antallet af TP, TN, FP, FN og brug disse tal til at beregne følsomhed, specificitet og nøjagtighed af klassificeringsresultaterne. Gør det manuelt uden brug af programmering og rapporter resultaterne.\n",
    "\n",
    "### Kvalitet af klassificering (fortsæt)\n",
    "\n",
    "Lad os kombinere al kode sammen til en Python funktion, som vil beregne alle statistikker baseret på data frame med klassificeringsresultater. Det vil antage, at dataframen har to kolonner, hvor den første kolonne indeholder referenceklassens etiket og den anden kolonne indeholder de forudsigede etiketter.\n",
    "\n",
    "Funktionen vil fungere for enhver målklassificering givet som et argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_stat(res, target_class):\n",
    "\n",
    "    ref = res[\"Reference\"]\n",
    "    pred = res[\"Prediction\"]\n",
    "\n",
    "    TP = sum((ref == target_class) & (pred == target_class))\n",
    "    TN = sum((ref != target_class) & (pred != target_class))\n",
    "    FP = sum((ref != target_class) & (pred == target_class))\n",
    "    FN = sum((ref == target_class) & (pred != target_class))\n",
    "\n",
    "    sens = TP / (TP + FN)\n",
    "    spec = TN / (TN + FP)\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "    # return all statistics in form of dictionary\n",
    "    return {\n",
    "        \"target\": target_class,\n",
    "        \"TP\": TP,\n",
    "        \"TN\": TN,\n",
    "        \"FP\": FP,\n",
    "        \"FN\": FN,\n",
    "        \"sens\": sens,\n",
    "        \"spec\": spec,\n",
    "        \"acc\": acc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lad os se, om det virker for vores eksempel. Lad os få statistikker både for træningssættet og for testsættet separat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stat = class_stat(res, \"virginica\")\n",
    "test_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu skal vi se, hvordan brugen af forskellige tærskelværdier påvirker klassifikationskvaliteten. Koden nedenfor ligner det, vi brugte før, men er bare skrevet på en mere kompakt måde. Prøv forskellige tærskelværdier og se, hvor godt de klarer sig for testdatasættet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.70\n",
    "\n",
    "pred = df_isvirginica(d_test, threshold)\n",
    "ref = d_test[\"Species\"]\n",
    "res = pd.DataFrame({\"Reference\": ref, \"Prediction\": pred})\n",
    "test_stat = class_stat(res, \"virginica\")\n",
    "test_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prøv nu det samme for træningssættet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.70\n",
    "\n",
    "pred = df_isvirginica(d_train, threshold)\n",
    "ref = d_train[\"Species\"]\n",
    "res = pd.DataFrame({\"Reference\": ref, \"Prediction\": pred})\n",
    "train_stat = class_stat(res, \"virginica\")\n",
    "train_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Receiver operating characteristic\n",
    "\n",
    "Endelig lad os gøre følgende. Lad os prøve at ændre tærsklen og se, hvordan det påvirker sensitiviteten, specificiteten og nøjagtigheden. Lad os starte med 1,0 og derefter prøve alle tærskelværdier op til 2,0 med et trin på 0,1, så vi får i alt 11 resultater:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need numpy to make a sequence of threshold values\n",
    "import numpy as np\n",
    "\n",
    "# generate a sequence of 11 numbers between 1.0 and 2.0\n",
    "thresholds = np.linspace(1.0, 2.0, 11)\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare empty lists to save main statistics for each thresholds\n",
    "sens = []\n",
    "spec = []\n",
    "acc = []\n",
    "\n",
    "# save reference values into separate variable\n",
    "ref = d_test[\"Species\"]\n",
    "\n",
    "# apply different threshold values and save the results to the lists\n",
    "for t in thresholds:\n",
    "    pred = df_isvirginica(d_test, threshold = t)\n",
    "    res = pd.DataFrame({\"Reference\": ref, \"Prediction\": pred})\n",
    "    stat = class_stat(res, \"virginica\")\n",
    "\n",
    "    spec.append(stat[\"spec\"])\n",
    "    sens.append(stat[\"sens\"])\n",
    "    acc.append(stat[\"acc\"])\n",
    "\n",
    "# show the result\n",
    "(spec, sens, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lad os visualisere resultaterne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds, sens, marker=\"o\", label = \"sens\")\n",
    "plt.plot(thresholds, spec, marker=\"x\", label = \"spec\")\n",
    "plt.plot(thresholds, acc, marker=\"+\", label = \"acc\")\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu kan du træffe en informeret beslutning. For eksempel giver en tærskel på 1,4 alle tre statistikker, der er lig med 0,90. En mindre tærskel på 1,3 giver perfekt følsomhed, men reducerer specificiteten til 0,85. Den større tærskel, på 1,5, giver perfekt specificitet, men reducerer følsomheden til 0,80.\n",
    "\n",
    "Der er også en anden måde at vise disse resultater på — lav et linjediagram, hvor følsomheden afhænger af (1 - specificitet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we convert list to NumPy array in order to make\n",
    "# the arithmetic operation (1 - spec) easier\n",
    "spec = np.array(spec)\n",
    "\n",
    "# show the plot\n",
    "plt.plot(1 - spec, sens, marker = \"o\")\n",
    "\n",
    "# make plot look nicer\n",
    "plt.xlim((-0.1, 1.1))\n",
    "plt.ylim((-0.1, 1.1))\n",
    "plt.grid(color = \"lightgray\")\n",
    "plt.xlabel(\"1 - specificity\")\n",
    "plt.ylabel(\"sensitivity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denne graf kaldes *Receiver operating characteristic* (ROC) graf. Jo tættere kurven er på top højre hjørne, jo bedre er modellen. Dog for at gøre denne graf komplet, er det nødvendigt at bruge et bredere interval af tærskelværdier, så begge statistikker går fra 0 til 1. Forsøg at implementere dette."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flersklasse klassificering\n",
    "\n",
    "Nu skal vi lave en klassifikationsmodel, som vil give en af klassens etiketter som svar, så den vil skelne mellem alle blomster blandt de tre arter. Denne tilgang er kendt som *flersklasse klassificering*.\n",
    "\n",
    "Først og fremmest lad os se på de to spredningsdiagrammer nedenfor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "iris_scatter(d_train, x = \"SepalLength\", y = \"SepalWidth\")\n",
    "plt.subplot(1, 2, 2)\n",
    "iris_scatter(d_train, x = \"PetalLength\", y = \"PetalWidth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tilsyneladende kan vi bruge blomstblade målinger til diskriminering. Setosa kan tydeligt skelnes ved at bruge en tærskel langs Blomsterblad længde, ved f.eks. en tærskel på 2.5. Vi har allerede en løsning for virginica (vi vil bruge den samme tærskel på 1.7). Og hvis ingen af de to betingelser er opfyldt, vil blomsten blive genkendt som versicolor.\n",
    "\n",
    "Sådan kan det skematisk vises som et følgende flowchart:\n",
    "\n",
    "<img src=\"illustrations/tree.png\" style=\"width:600px\">\n",
    "\n",
    "Sådanne modeller baseret på et sæt af indlejrede tærskler kaldes [Decision Trees](https://en.wikipedia.org/wiki/Decision_tree).\n",
    "\n",
    "Lad os implementere det som følgende funktion for en enkelt række fra data rammen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flower_classifier(flower):\n",
    "    if flower[\"PetalLength\"] < 2.5:\n",
    "        return \"setosa\"\n",
    "    elif flower[\"PetalWidth\"] > 1.7:\n",
    "        return \"virginica\"\n",
    "    else:\n",
    "        return \"versicolor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Og lad os nu lave en funktion, der anvender denne klassificering på alle rækker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_classifier(d):\n",
    "    predictions = []\n",
    "    for index, flower in d.iterrows():\n",
    "        predictions.append(flower_classifier(flower))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Og test det:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = d_test[\"Species\"]\n",
    "pred = df_classifier(d_test)\n",
    "res = pd.DataFrame({\"Reference\": ref, \"Prediction\": pred})\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Og det virker! Nu skal vi bare beregne kvalitetsstatistikkerne for klassificeringen for hver af klasserne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat =[]\n",
    "for class_label in ref.unique():\n",
    "    stat.append(class_stat(res, class_label))\n",
    "stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dette er det. I næste klasse vil vi tale om, hvordan man opretter en model, som selv definerer klassifikationsreglen ved at lære af data.\n",
    "\n",
    "### Øvelse\n",
    "\n",
    "Implementer beslutningstræet, som vil bruge tre betingelser i stedet for to. Lav først en tegning og implementer det derefter i Python og test det. Diskuter fordele og ulemper ved denne løsning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
