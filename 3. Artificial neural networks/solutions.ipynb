{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions for exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "*Case 1*\n",
    "\n",
    "| $y$ | $\\hat{y}$ | $(y - \\hat{y})$ | $(y - \\hat{y})^2$ |\n",
    "| --:| ---------:| ---------------:| -----------------:|\n",
    "| -1 | 0.2 | -1.2 | 1.44 |\n",
    "| -1 | 0.4 | -1.4 | 1.96 |\n",
    "|  1 | -0.2 | 1.2 | 1.44 |\n",
    "|  1 | -0.4 | 1.4 | 1.96 |\n",
    "\n",
    "$MSE = (1.44 + 1.96 + 1.44 + 1.96) / 4 = 6.8/4 = 1.7$\n",
    "\n",
    "*Case 2*\n",
    "\n",
    "| $y$ | $\\hat{y}$ | $(y - \\hat{y})$ | $(y - \\hat{y})^2$ |\n",
    "| --:| ---------:| ---------------:| -----------------:|\n",
    "|  1 | 0.2 | 0.8 | 0.64 |\n",
    "|  1 | 0.4 | 0.6 | 0.36 |\n",
    "| -1 | -0.2 | -0.8 | 0.64 |\n",
    "| -1 | -0.4 | -0.6 | 0.36 |\n",
    "\n",
    "$MSE = (0.64 + 0.36 + 0.64 + 0.36) / 4 = 2/4 = 0.5$\n",
    "\n",
    "In the second case MSE is more than three time smaller indicating improvements in the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of the train function from the class\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def train(model, X_train, labels_train, X_val, labels_val, nepochs = 100, lr = 0.01):\n",
    "    \"\"\" trains any classification model using provided data, number of epochs and learning rate \"\"\"\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(nepochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        labels_predicted = model(X_train)\n",
    "        loss = loss_function(labels_predicted, labels_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss = loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        labels_predicted = model(X_val)\n",
    "        loss = loss_function(labels_predicted, labels_val)\n",
    "        val_loss = loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch}, train loss: {train_loss:.4f} - validation loss {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of the predict function form the class\n",
    "\n",
    "def predict(model, X):\n",
    "    \"\"\" get ANN model and tensor with predictors and returns predicted class label indices \"\"\"\n",
    "    model.eval()\n",
    "    output = model.forward(X)\n",
    "    _, labels = torch.max(output, 1)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class with the model\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiClassModel(nn.Module):\n",
    "    \"\"\" class for three layers ANN \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MultiClassModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(4, 8)  # first layer: 4 inputs and 8 outputs\n",
    "        self.layer2 = nn.Linear(8, 16)  # first layer: 8 inputs and 16 outputs\n",
    "        self.layer3 = nn.Linear(16, 3)  # first layer: 16 inputs and 3 outputs\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x)) # pass inputs through the first layer and apply ReLU activation\n",
    "        x = F.relu(self.layer2(x)) # pass output from layer 1 through the second layer + ReLU activation\n",
    "        y_hat = self.layer3(x) # pass output from layer 2 through the third layer (no relu)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data and split to subsets\n",
    "\n",
    "import pandas as pd\n",
    "d = pd.read_csv(\"Iris.csv\")\n",
    "\n",
    "classes = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "class_to_idx = {\"setosa\": 0, \"versicolor\": 1, \"virginica\": 2}\n",
    "\n",
    "X_values = d.iloc[:, 1:5].values\n",
    "X = torch.tensor(X_values).float()\n",
    "\n",
    "label_values = [class_to_idx[label] for label in d[\"Species\"]]\n",
    "labels = torch.tensor(label_values).long()\n",
    "\n",
    "train_ind = d[\"Id\"] % 5 != 0\n",
    "test_ind = d[\"Id\"] % 5 == 0\n",
    "\n",
    "X_train = X[train_ind, :]\n",
    "labels_train = labels[train_ind]\n",
    "\n",
    "X_test = X[test_ind, :]\n",
    "labels_test = labels[test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model = MultiClassModel()\n",
    "train(model, X_train, labels_train, X_test, labels_test, nepochs = 1000, lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load new data and show it\n",
    "import pandas as pd\n",
    "d_new = pd.read_csv(\"IrisHeatmap.csv\")\n",
    "d_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the values and convert them to torch tensor\n",
    "X_new_values = d_new.iloc[:, 0:4].values\n",
    "X_new = torch.tensor(X_new_values).float()\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for the new values\n",
    "labels_new = predict(model, X_new)\n",
    "labels_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split tensor with the new values to subset based on predicted labels\n",
    "se_new = X_new[labels_new == 0]\n",
    "vi_new = X_new[labels_new == 1]\n",
    "ve_new = X_new[labels_new == 2]\n",
    "\n",
    "# split tensor with the training set values to subsets\n",
    "se_train = X_train[labels_train == 0]\n",
    "vi_train = X_train[labels_train == 1]\n",
    "ve_train = X_train[labels_train == 2]\n",
    "\n",
    "# split tensor with the test set values to subsets\n",
    "se_test = X_test[labels_test == 0]\n",
    "vi_test = X_test[labels_test == 1]\n",
    "ve_test = X_test[labels_test == 2]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# show the predictor points using semi transparent colors\n",
    "plt.scatter(se_new[:, 2], se_new[:, 3], alpha=0.15, color=\"red\")\n",
    "plt.scatter(vi_new[:, 2], vi_new[:, 3], alpha=0.15, color=\"green\")\n",
    "plt.scatter(ve_new[:, 2], ve_new[:, 3], alpha=0.15, color=\"blue\")\n",
    "\n",
    "# show the training set points using circles\n",
    "plt.scatter(se_train[:, 2], se_train[:, 3], color=\"red\")\n",
    "plt.scatter(vi_train[:, 2], vi_train[:, 3], color=\"green\")\n",
    "plt.scatter(ve_train[:, 2], ve_train[:, 3], color=\"blue\")\n",
    "\n",
    "# show the test set points using crosses\n",
    "plt.scatter(se_test[:, 2], se_test[:, 3], marker=\"x\", color=\"red\")\n",
    "plt.scatter(vi_test[:, 2], vi_test[:, 3], marker=\"x\", color=\"green\")\n",
    "plt.scatter(ve_test[:, 2], ve_test[:, 3], marker=\"x\", color=\"blue\")\n",
    "\n",
    "plt.xlabel(\"Petal length, cm\")\n",
    "plt.ylabel(\"Petal width, cm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
